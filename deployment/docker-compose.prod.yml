# deployment/docker-compose.prod.yml
# AI Stock Selector - Production Docker Compose Configuration
version: '3.8'

services:
  # ===== DATABASE SERVICES =====
  postgres:
    image: postgres:15-alpine
    container_name: ai_stock_postgres_prod
    environment:
      POSTGRES_USER: ${POSTGRES_USER}
      POSTGRES_PASSWORD: ${POSTGRES_PASSWORD}
      POSTGRES_DB: ${POSTGRES_DB}
      POSTGRES_INITDB_ARGS: "--encoding=UTF-8 --lc-collate=C --lc-ctype=C"
    volumes:
      - postgres_prod_data:/var/lib/postgresql/data
      - ../database_schema.sql:/docker-entrypoint-initdb.d/01-schema.sql
    networks:
      - ai_stock_network
    restart: unless-stopped
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U ${POSTGRES_USER} -d ${POSTGRES_DB}"]
      interval: 30s
      timeout: 10s
      retries: 3
    deploy:
      resources:
        limits:
          memory: 2G
        reservations:
          memory: 1G

  influxdb:
    image: influxdb:2.7-alpine
    container_name: ai_stock_influxdb_prod
    environment:
      DOCKER_INFLUXDB_INIT_MODE: setup
      DOCKER_INFLUXDB_INIT_USERNAME: ${INFLUXDB_USER}
      DOCKER_INFLUXDB_INIT_PASSWORD: ${INFLUXDB_PASSWORD}
      DOCKER_INFLUXDB_INIT_ORG: ${INFLUXDB_ORG}
      DOCKER_INFLUXDB_INIT_BUCKET: ${INFLUXDB_BUCKET}
      DOCKER_INFLUXDB_INIT_ADMIN_TOKEN: ${INFLUXDB_TOKEN}
    volumes:
      - influxdb_prod_data:/var/lib/influxdb2
      - influxdb_prod_config:/etc/influxdb2
    networks:
      - ai_stock_network
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "influx", "ping"]
      interval: 30s
      timeout: 10s
      retries: 3
    deploy:
      resources:
        limits:
          memory: 1G
        reservations:
          memory: 512M

  redis:
    image: redis:7-alpine
    container_name: ai_stock_redis_prod
    command: redis-server --appendonly yes --maxmemory 1gb --maxmemory-policy allkeys-lru --requirepass ${REDIS_PASSWORD}
    volumes:
      - redis_prod_data:/data
    networks:
      - ai_stock_network
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "redis-cli", "--no-auth-warning", "-a", "${REDIS_PASSWORD}", "ping"]
      interval: 30s
      timeout: 10s
      retries: 3
    deploy:
      resources:
        limits:
          memory: 1G
        reservations:
          memory: 512M

  # ===== BACKEND SERVICES =====
  backend:
    build:
      context: ../backend
      dockerfile: Dockerfile
    container_name: ai_stock_backend_prod
    env_file:
      - .env.prod
    environment:
      ENVIRONMENT: production
      DATABASE_URL: postgresql://${POSTGRES_USER}:${POSTGRES_PASSWORD}@postgres:5432/${POSTGRES_DB}
      REDIS_URL: redis://:${REDIS_PASSWORD}@redis:6379/0
      INFLUXDB_URL: http://influxdb:8086
    volumes:
      - backend_prod_logs:/app/logs
    depends_on:
      postgres:
        condition: service_healthy
      redis:
        condition: service_healthy
      influxdb:
        condition: service_healthy
    networks:
      - ai_stock_network
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8000/health"]
      interval: 30s
      timeout: 10s
      retries: 3
    deploy:
      resources:
        limits:
          memory: 2G
        reservations:
          memory: 1G

  # ===== CELERY SERVICES =====
  celery_worker:
    build:
      context: ../backend
      dockerfile: Dockerfile
    container_name: ai_stock_celery_worker_prod
    command: celery -A celery_app worker --loglevel=warning --concurrency=4 --queues=data_update,calculations,ai_processing,maintenance
    env_file:
      - .env.prod
    environment:
      ENVIRONMENT: production
      DATABASE_URL: postgresql://${POSTGRES_USER}:${POSTGRES_PASSWORD}@postgres:5432/${POSTGRES_DB}
      REDIS_URL: redis://:${REDIS_PASSWORD}@redis:6379/0
      CELERY_BROKER_URL: redis://:${REDIS_PASSWORD}@redis:6379/1
      CELERY_RESULT_BACKEND: redis://:${REDIS_PASSWORD}@redis:6379/1
    volumes:
      - ../data_collector:/app/data_collector
      - celery_prod_logs:/app/logs
    depends_on:
      postgres:
        condition: service_healthy
      redis:
        condition: service_healthy
      backend:
        condition: service_healthy
    networks:
      - ai_stock_network
    restart: unless-stopped
    deploy:
      resources:
        limits:
          memory: 1G
        reservations:
          memory: 512M

  celery_beat:
    build:
      context: ../backend
      dockerfile: Dockerfile
    container_name: ai_stock_celery_beat_prod
    command: celery -A celery_app beat --loglevel=warning
    env_file:
      - .env.prod
    environment:
      ENVIRONMENT: production
      DATABASE_URL: postgresql://${POSTGRES_USER}:${POSTGRES_PASSWORD}@postgres:5432/${POSTGRES_DB}
      REDIS_URL: redis://:${REDIS_PASSWORD}@redis:6379/0
      CELERY_BROKER_URL: redis://:${REDIS_PASSWORD}@redis:6379/1
      CELERY_RESULT_BACKEND: redis://:${REDIS_PASSWORD}@redis:6379/1
    volumes:
      - celery_beat_prod_schedule:/app/schedule
    depends_on:
      postgres:
        condition: service_healthy
      redis:
        condition: service_healthy
      celery_worker:
        condition: service_started
    networks:
      - ai_stock_network
    restart: unless-stopped
    deploy:
      resources:
        limits:
          memory: 512M
        reservations:
          memory: 256M

  # ===== FRONTEND SERVICE =====
  frontend:
    build:
      context: ../frontend
      dockerfile: Dockerfile
    container_name: ai_stock_frontend_prod
    environment:
      - NODE_ENV=production
      - REACT_APP_API_BASE_URL=https://${DOMAIN_NAME}
    depends_on:
      backend:
        condition: service_healthy
    networks:
      - ai_stock_network
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:3000/"]
      interval: 30s
      timeout: 10s
      retries: 3
    deploy:
      resources:
        limits:
          memory: 512M
        reservations:
          memory: 256M

  # ===== DATA COLLECTOR SERVICE =====
  data_collector:
    build:
      context: ../data_collector
      dockerfile: Dockerfile
    container_name: ai_stock_data_collector_prod
    env_file:
      - .env.prod
    environment:
      ENVIRONMENT: production
      DATABASE_URL: postgresql://${POSTGRES_USER}:${POSTGRES_PASSWORD}@postgres:5432/${POSTGRES_DB}
      REDIS_URL: redis://:${REDIS_PASSWORD}@redis:6379/0
    volumes:
      - ../backend/app:/app/backend_app
      - data_collector_prod_logs:/app/logs
    depends_on:
      postgres:
        condition: service_healthy
      redis:
        condition: service_healthy
    networks:
      - ai_stock_network
    restart: unless-stopped
    deploy:
      resources:
        limits:
          memory: 1G
        reservations:
          memory: 512M

  # ===== REVERSE PROXY =====
  nginx:
    image: nginx:alpine
    container_name: ai_stock_nginx_prod
    ports:
      - "80:80"
      - "443:443"
    volumes:
      - ../nginx/nginx.conf:/etc/nginx/nginx.conf
      - ./ssl:/etc/nginx/ssl
      - nginx_prod_logs:/var/log/nginx
    depends_on:
      - frontend
      - backend
    networks:
      - ai_stock_network
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "nginx", "-t"]
      interval: 30s
      timeout: 10s
      retries: 3
    deploy:
      resources:
        limits:
          memory: 256M
        reservations:
          memory: 128M

  # ===== MONITORING SERVICES =====
  prometheus:
    image: prom/prometheus:latest
    container_name: ai_stock_prometheus_prod
    ports:
      - "9090:9090"
    volumes:
      - ../monitoring/prometheus.yml:/etc/prometheus/prometheus.yml
      - prometheus_prod_data:/prometheus
    command:
      - '--config.file=/etc/prometheus/prometheus.yml'
      - '--storage.tsdb.path=/prometheus'
      - '--web.console.libraries=/etc/prometheus/console_libraries'
      - '--web.console.templates=/etc/prometheus/consoles'
      - '--storage.tsdb.retention.time=200h'
      - '--web.enable-lifecycle'
    networks:
      - ai_stock_network
    restart: unless-stopped
    profiles:
      - monitoring

  grafana:
    image: grafana/grafana:latest
    container_name: ai_stock_grafana_prod
    ports:
      - "3001:3000"
    environment:
      - GF_SECURITY_ADMIN_USER=${GRAFANA_USER}
      - GF_SECURITY_ADMIN_PASSWORD=${GRAFANA_PASSWORD}
    volumes:
      - grafana_prod_data:/var/lib/grafana
      - ../monitoring/grafana/dashboards:/etc/grafana/provisioning/dashboards
      - ../monitoring/grafana/datasources:/etc/grafana/provisioning/datasources
    depends_on:
      - prometheus
    networks:
      - ai_stock_network
    restart: unless-stopped
    profiles:
      - monitoring

# ===== VOLUMES =====
volumes:
  postgres_prod_data:
    driver: local
  influxdb_prod_data:
    driver: local
  influxdb_prod_config:
    driver: local
  redis_prod_data:
    driver: local
  backend_prod_logs:
    driver: local
  celery_prod_logs:
    driver: local
  celery_beat_prod_schedule:
    driver: local
  data_collector_prod_logs:
    driver: local
  nginx_prod_logs:
    driver: local
  prometheus_prod_data:
    driver: local
  grafana_prod_data:
    driver: local

# ===== NETWORKS =====
networks:
  ai_stock_network:
    driver: bridge
    ipam:
      config:
        - subnet: 172.21.0.0/16